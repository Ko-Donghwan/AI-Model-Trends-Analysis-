from scraping.web_scraper import WebScraper
from scraping.model_parser import ModelParser
from processing.download_parser import DownloadGraphParser
from data.model_data import ModelData
from storage.csv_handler import CSVHandler

class HuggingFaceModelDownloader:
    """Hugging Face ëª¨ë¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, csv_file: str, output_file: str):
        self.scraper = WebScraper()
        self.csv_handler = CSVHandler(output_file)
        self.input_csv = CSVHandler(csv_file)  # ì…ë ¥ CSV íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
    
    def fetch_and_save_models(self) -> None:
        """CSV íŒŒì¼ì—ì„œ ëª¨ë¸ IDë¥¼ ì½ì–´ì™€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° ì €ì¥"""
        df = self.input_csv.load_data()  # CSVì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        if 'id' not in df.columns:
            raise KeyError("ğŸš¨ CSV íŒŒì¼ì— 'id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        for model_id in df['id']:
            print(f"ğŸ”„ ëª¨ë¸ ìˆ˜ì§‘ ì¤‘: {model_id}")
            self.fetch_and_save_model(model_id)

    def fetch_and_save_model(self, model_name: str) -> None:
        """ë‹¨ì¼ ëª¨ë¸ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥"""
        url = f'https://huggingface.co/{model_name}'
        soup = self.scraper.get_page_content(url)
        task, total_downloads, path_data = ModelParser.extract_model_data(soup)

        daily_downloads = [0] * 30
        if path_data and total_downloads:
            points = DownloadGraphParser.parse_path_data(path_data)
            daily_downloads = DownloadGraphParser.normalize_downloads(points, int(total_downloads))

        model_data = ModelData(model_name, task, daily_downloads)
        self.csv_handler.save_model_data(model_data)
