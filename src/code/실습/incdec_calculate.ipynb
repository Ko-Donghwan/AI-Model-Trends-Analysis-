{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ge_10000_df: 84\n",
      "Length of ge_1000_df: 303\n",
      "Length of ge_100_df: 769\n",
      "Length of ge_50_df: 400\n",
      "Length of ge_10_df: 1758\n",
      "Length of ge_0_df: 2075\n",
      "Spearman correlation between Total Downloads and Growth Rate: 0.6851864193315802, P-value: 0.0\n",
      "Spearman correlation between Total Downloads and Consistency: 0.8253896429115307, P-value: 0.0\n",
      "Spearman correlation between Growth Rate and Consistency: 0.9399274348585726, P-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# 1달간 다운로드 증감량 계산\n",
    "def incdec_calculate(df):\n",
    "    for day in range(1, 30):\n",
    "        df.loc[:, f\"Change_{day+1}Day\"] = df.loc[:, f\"{day+1}Day\"] - df.loc[:, f\"{day}Day\"]\n",
    "    return df\n",
    "\n",
    "# 1달간 다운로드 상승률 계산\n",
    "def incdecRate_calculate(df):\n",
    "    for day in range(1, 30):\n",
    "        df[f\"ChangeRate_{day+1}Day\"] = (df[f\"Change_{day+1}Day\"] / df[f\"{day}Day\"]) * 100\n",
    "    return df\n",
    "\n",
    "# 최근 29일간 누적 다운로드 수 계산\n",
    "def cumulative_changes(df):\n",
    "    df['Cumulative_Recent_29Day'] = df.loc[:, '1Day':'29Day'].cumsum(axis=1).iloc[:, -1]\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('20240617_Daily_Download.csv')\n",
    "df_incdec = incdec_calculate(df)\n",
    "df_incdec_Rate = incdecRate_calculate(df_incdec) \n",
    "\n",
    "df_incdec_Rate_copy = df_incdec_Rate.copy()\n",
    "\n",
    "weights = {\n",
    "    'ChangeRate_2Day': 1, 'ChangeRate_3Day': 2, 'ChangeRate_4Day': 3,\n",
    "    'ChangeRate_5Day': 4, 'ChangeRate_6Day': 5, 'ChangeRate_7Day': 6,\n",
    "    'ChangeRate_8Day': 7, 'ChangeRate_9Day': 8, 'ChangeRate_10Day': 9, \n",
    "    'ChangeRate_11Day': 10, 'ChangeRate_12Day': 15, 'ChangeRate_13Day': 20,\n",
    "    'ChangeRate_14Day': 25, 'ChangeRate_15Day': 30, 'ChangeRate_16Day': 35,\n",
    "    'ChangeRate_17Day': 40, 'ChangeRate_18Day': 50, 'ChangeRate_19Day': 60,\n",
    "    'ChangeRate_20Day': 71, 'ChangeRate_21Day': 75, 'ChangeRate_22Day': 79,\n",
    "    'ChangeRate_23Day': 83, 'ChangeRate_24Day': 87, 'ChangeRate_25Day': 90,\n",
    "    'ChangeRate_26Day': 93, 'ChangeRate_27Day': 96, 'ChangeRate_28Day': 98,\n",
    "    'ChangeRate_29Day': 100\n",
    "}\n",
    "\n",
    "df_incdec_Rate_copy.loc[:, 'Change_2Day_to_29Day_WeightedSum'] = sum(\n",
    "    df_incdec_Rate_copy[col] * weight for col, weight in weights.items()\n",
    ") / sum(weights.values())\n",
    "\n",
    "df_incdec = df_incdec_Rate_copy.sort_values(by='Change_2Day_to_29Day_WeightedSum', ascending=False)\n",
    "\n",
    "df_incdec['inc_score'] = range(len(df_incdec), 0, -1)\n",
    "days_columns = [f\"{i+1}Day\" for i in range(30)]\n",
    "\n",
    "ge_10000_df = df_incdec[df_incdec[days_columns].ge(10000).all(axis=1)]\n",
    "ge_10000_df_cum = ge_10000_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "ge_1000_df = df_incdec[df_incdec[days_columns].ge(1000).all(axis=1)]\n",
    "ge_1000_df = ge_1000_df[~ge_1000_df.index.isin(ge_10000_df.index)]\n",
    "ge_1000_df_cum = ge_1000_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "ge_100_df = df_incdec[df_incdec[days_columns].ge(100).all(axis=1)]\n",
    "ge_100_df = ge_100_df[~ge_100_df.index.isin(ge_1000_df.index.union(ge_10000_df.index))]\n",
    "ge_100_df_cum = ge_100_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "ge_50_df = df_incdec[df_incdec[days_columns].ge(50).all(axis=1)]\n",
    "ge_50_df = ge_50_df[~ge_50_df.index.isin(ge_100_df.index.union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "ge_50_df_cum = ge_50_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "ge_10_df = df_incdec[df_incdec[days_columns].ge(10).all(axis=1)]\n",
    "ge_10_df = ge_10_df[~ge_10_df.index.isin(ge_50_df.index.union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "ge_10_df_cum = ge_10_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "ge_0_df = df_incdec[df_incdec[days_columns].ge(0).all(axis=1)]\n",
    "ge_0_df = ge_0_df[~ge_0_df.index.isin(ge_10_df.index.union(ge_50_df.index).union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "ge_0_df_cum = ge_0_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "dfs = [ge_10000_df_cum, ge_1000_df_cum, ge_100_df_cum, ge_50_df_cum, ge_10_df_cum, ge_0_df_cum]\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "merged_df['inc_sort_score'] = range(len(merged_df), 0, -1)\n",
    "\n",
    "merged_df_copy = merged_df.copy()\n",
    "df_incdec_WeightSum_cumulative = cumulative_changes(merged_df_copy)\n",
    "sorted_df = df_incdec_WeightSum_cumulative.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "sorted_df['sum_score'] = range(len(sorted_df), 0, -1)\n",
    "\n",
    "# 상위 데이터프레임에 포함된 행을 빼는 방식으로 데이터프레임 생성\n",
    "ge_10000_df = sorted_df[sorted_df[days_columns].ge(10000).all(axis=1)]\n",
    "ge_10000_df_cum = ge_10000_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "ge_1000_df = sorted_df[sorted_df[days_columns].ge(1000).all(axis=1)]\n",
    "ge_1000_df = ge_1000_df[~ge_1000_df.index.isin(ge_10000_df.index)]\n",
    "ge_1000_df_cum = ge_1000_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "ge_100_df = sorted_df[sorted_df[days_columns].ge(100).all(axis=1)]\n",
    "ge_100_df = ge_100_df[~ge_100_df.index.isin(ge_1000_df.index.union(ge_10000_df.index))]\n",
    "ge_100_df_cum = ge_100_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "ge_50_df = sorted_df[sorted_df[days_columns].ge(50).all(axis=1)]\n",
    "ge_50_df = ge_50_df[~ge_50_df.index.isin(ge_100_df.index.union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "ge_50_df_cum = ge_50_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "ge_10_df = sorted_df[sorted_df[days_columns].ge(10).all(axis=1)]\n",
    "ge_10_df = ge_10_df[~ge_10_df.index.isin(ge_50_df.index.union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "ge_10_df_cum = ge_10_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "ge_0_df = sorted_df[sorted_df[days_columns].ge(0).all(axis=1)]\n",
    "ge_0_df = ge_0_df[~ge_0_df.index.isin(ge_10_df.index.union(ge_50_df.index).union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "ge_0_df_cum = ge_0_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "len_ge_10000_df = len(ge_10000_df_cum)\n",
    "len_ge_1000_df = len(ge_1000_df_cum)\n",
    "len_ge_100_df = len(ge_100_df_cum)\n",
    "len_ge_50_df = len(ge_50_df_cum)\n",
    "len_ge_10_df = len(ge_10_df_cum)\n",
    "len_ge_0_df = len(ge_0_df_cum)\n",
    "\n",
    "print(f\"Length of ge_10000_df: {len_ge_10000_df}\")\n",
    "print(f\"Length of ge_1000_df: {len_ge_1000_df}\")\n",
    "print(f\"Length of ge_100_df: {len_ge_100_df}\")\n",
    "print(f\"Length of ge_50_df: {len_ge_50_df}\")\n",
    "print(f\"Length of ge_10_df: {len_ge_10_df}\")\n",
    "print(f\"Length of ge_0_df: {len_ge_0_df}\")\n",
    "\n",
    "# 병합을 위한 데이터프레임 리스트\n",
    "dfs = [ge_10000_df_cum, ge_1000_df_cum, ge_100_df_cum, ge_50_df_cum, ge_10_df_cum, ge_0_df_cum]\n",
    "\n",
    "# 모든 데이터프레임을 병합\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "merged_df['consistency_score'] = range(len(merged_df), 0, -1)\n",
    "merged_df = merged_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "sum_score_list = merged_df['sum_score'].to_list()\n",
    "inc_score_list = merged_df['inc_sort_score'].to_list()\n",
    "consistency_score_list = merged_df['consistency_score'].to_list()\n",
    "\n",
    "data = {\n",
    "    'Total_Downloads_Rank': sum_score_list,\n",
    "    'Growth_Rate_Rank': inc_score_list,\n",
    "    'Consistency_Rank': consistency_score_list\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 스피어만 순위 상관계수 계산\n",
    "spearman_corr_total_growth, p_value_total_growth = stats.spearmanr(df['Total_Downloads_Rank'], df['Growth_Rate_Rank'])\n",
    "spearman_corr_total_consistency, p_value_total_consistency = stats.spearmanr(df['Total_Downloads_Rank'], df['Consistency_Rank'])\n",
    "spearman_corr_growth_consistency, p_value_growth_consistency = stats.spearmanr(df['Growth_Rate_Rank'], df['Consistency_Rank'])\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Spearman correlation between Total Downloads and Growth Rate: {spearman_corr_total_growth}, P-value: {p_value_total_growth}\")\n",
    "print(f\"Spearman correlation between Total Downloads and Consistency: {spearman_corr_total_consistency}, P-value: {p_value_total_consistency}\")\n",
    "print(f\"Spearman correlation between Growth Rate and Consistency: {spearman_corr_growth_consistency}, P-value: {p_value_growth_consistency}\")\n",
    "\n",
    "merged_df['row_mean'] = merged_df[['inc_sort_score', 'sum_score', 'consistency_score']].mean(axis=1)\n",
    "mean_df = merged_df.sort_values(by='row_mean', ascending=False)\n",
    "mean_df.to_csv('20240616_모델_순위.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "class DownloadDataProcessor:\n",
    "    def __init__(self, file_path):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.days_columns = [f\"{i+1}Day\" for i in range(30)]\n",
    "        self.weights = {\n",
    "            'ChangeRate_2Day': 1, 'ChangeRate_3Day': 2, 'ChangeRate_4Day': 3,\n",
    "            'ChangeRate_5Day': 4, 'ChangeRate_6Day': 5, 'ChangeRate_7Day': 6,\n",
    "            'ChangeRate_8Day': 7, 'ChangeRate_9Day': 8, 'ChangeRate_10Day': 9, \n",
    "            'ChangeRate_11Day': 10, 'ChangeRate_12Day': 15, 'ChangeRate_13Day': 20,\n",
    "            'ChangeRate_14Day': 25, 'ChangeRate_15Day': 30, 'ChangeRate_16Day': 35,\n",
    "            'ChangeRate_17Day': 40, 'ChangeRate_18Day': 50, 'ChangeRate_19Day': 60,\n",
    "            'ChangeRate_20Day': 71, 'ChangeRate_21Day': 75, 'ChangeRate_22Day': 79,\n",
    "            'ChangeRate_23Day': 83, 'ChangeRate_24Day': 87, 'ChangeRate_25Day': 90,\n",
    "            'ChangeRate_26Day': 93, 'ChangeRate_27Day': 96, 'ChangeRate_28Day': 98,\n",
    "            'ChangeRate_29Day': 100\n",
    "        }\n",
    "        \n",
    "    def incdec_calculate(self):\n",
    "        for day in range(1, 30):\n",
    "            self.df.loc[:, f\"Change_{day+1}Day\"] = self.df.loc[:, f\"{day+1}Day\"] - self.df.loc[:, f\"{day}Day\"]\n",
    "        return self.df\n",
    "\n",
    "    def incdecRate_calculate(self):\n",
    "        for day in range(1, 30):\n",
    "            self.df[f\"ChangeRate_{day+1}Day\"] = (self.df[f\"Change_{day+1}Day\"] / self.df[f\"{day}Day\"]) * 100\n",
    "        return self.df\n",
    "\n",
    "    def cumulative_changes(self):\n",
    "        self.df['Cumulative_Recent_29Day'] = self.df.loc[:, '1Day':'29Day'].cumsum(axis=1).iloc[:, -1]\n",
    "        return self.df\n",
    "\n",
    "    def process_data(self):\n",
    "        self.incdec_calculate()\n",
    "        self.incdecRate_calculate()\n",
    "\n",
    "        self.df['Change_2Day_to_29Day_WeightedSum'] = sum(\n",
    "            self.df[col] * weight for col, weight in self.weights.items()\n",
    "        ) / sum(self.weights.values())\n",
    "\n",
    "        self.df = self.df.sort_values(by='Change_2Day_to_29Day_WeightedSum', ascending=False)\n",
    "        self.df['inc_score'] = range(len(self.df), 0, -1)\n",
    "\n",
    "        ge_10000_df = self.df[self.df[self.days_columns].ge(10000).all(axis=1)]\n",
    "        ge_10000_df_cum = ge_10000_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "        ge_1000_df = self.df[self.df[self.days_columns].ge(1000).all(axis=1)]\n",
    "        ge_1000_df = ge_1000_df[~ge_1000_df.index.isin(ge_10000_df.index)]\n",
    "        ge_1000_df_cum = ge_1000_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "        ge_100_df = self.df[self.df[self.days_columns].ge(100).all(axis=1)]\n",
    "        ge_100_df = ge_100_df[~ge_100_df.index.isin(ge_1000_df.index.union(ge_10000_df.index))]\n",
    "        ge_100_df_cum = ge_100_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "        ge_50_df = self.df[self.df[self.days_columns].ge(50).all(axis=1)]\n",
    "        ge_50_df = ge_50_df[~ge_50_df.index.isin(ge_100_df.index.union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "        ge_50_df_cum = ge_50_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "        ge_10_df = self.df[self.df[self.days_columns].ge(10).all(axis=1)]\n",
    "        ge_10_df = ge_10_df[~ge_10_df.index.isin(ge_50_df.index.union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "        ge_10_df_cum = ge_10_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "        ge_0_df = self.df[self.df[self.days_columns].ge(0).all(axis=1)]\n",
    "        ge_0_df = ge_0_df[~ge_0_df.index.isin(ge_10_df.index.union(ge_50_df.index).union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "        ge_0_df_cum = ge_0_df.sort_values(by='inc_score', ascending=False)\n",
    "\n",
    "        dfs = [ge_10000_df_cum, ge_1000_df_cum, ge_100_df_cum, ge_50_df_cum, ge_10_df_cum, ge_0_df_cum]\n",
    "        merged_df = pd.concat(dfs, ignore_index=True)\n",
    "        merged_df['inc_sort_score'] = range(len(merged_df), 0, -1)\n",
    "\n",
    "        self.df = self.cumulative_changes()\n",
    "        sorted_df = self.df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "        sorted_df['sum_score'] = range(len(sorted_df), 0, -1)\n",
    "\n",
    "        # 상위 데이터프레임에 포함된 행을 빼는 방식으로 데이터프레임 생성\n",
    "        ge_10000_df = sorted_df[sorted_df[self.days_columns].ge(10000).all(axis=1)]\n",
    "        ge_10000_df_cum = ge_10000_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "        ge_1000_df = sorted_df[sorted_df[self.days_columns].ge(1000).all(axis=1)]\n",
    "        ge_1000_df = ge_1000_df[~ge_1000_df.index.isin(ge_10000_df.index)]\n",
    "        ge_1000_df_cum = ge_1000_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "        ge_100_df = sorted_df[sorted_df[self.days_columns].ge(100).all(axis=1)]\n",
    "        ge_100_df = ge_100_df[~ge_100_df.index.isin(ge_1000_df.index.union(ge_10000_df.index))]\n",
    "        ge_100_df_cum = ge_100_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "        ge_50_df = sorted_df[sorted_df[self.days_columns].ge(50).all(axis=1)]\n",
    "        ge_50_df = ge_50_df[~ge_50_df.index.isin(ge_100_df.index.union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "        ge_50_df_cum = ge_50_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "        ge_10_df = sorted_df[sorted_df[self.days_columns].ge(10).all(axis=1)]\n",
    "        ge_10_df = ge_10_df[~ge_10_df.index.isin(ge_50_df.index.union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "        ge_10_df_cum = ge_10_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "        ge_0_df = sorted_df[sorted_df[self.days_columns].ge(0).all(axis=1)]\n",
    "        ge_0_df = ge_0_df[~ge_0_df.index.isin(ge_10_df.index.union(ge_50_df.index).union(ge_100_df.index).union(ge_1000_df.index).union(ge_10000_df.index))]\n",
    "        ge_0_df_cum = ge_0_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "        dfs = [ge_10000_df_cum, ge_1000_df_cum, ge_100_df_cum, ge_50_df_cum, ge_10_df_cum, ge_0_df_cum]\n",
    "        merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        merged_df['consistency_score'] = range(len(merged_df), 0, -1)\n",
    "        merged_df = merged_df.sort_values(by='Cumulative_Recent_29Day', ascending=False)\n",
    "\n",
    "        sum_score_list = merged_df['sum_score'].to_list()\n",
    "        inc_score_list = merged_df['inc_sort_score'].to_list()\n",
    "        consistency_score_list = merged_df['consistency_score'].to_list()\n",
    "\n",
    "        data = {\n",
    "            'Total_Downloads_Rank': sum_score_list,\n",
    "            'Growth_Rate_Rank': inc_score_list,\n",
    "            'Consistency_Rank': consistency_score_list\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # 스피어만 순위 상관계수 계산\n",
    "        spearman_corr_total_growth, p_value_total_growth = stats.spearmanr(df['Total_Downloads_Rank'], df['Growth_Rate_Rank'])\n",
    "        spearman_corr_total_consistency, p_value_total_consistency = stats.spearmanr(df['Total_Downloads_Rank'], df['Consistency_Rank'])\n",
    "        spearman_corr_growth_consistency, p_value_growth_consistency = stats.spearmanr(df['Growth_Rate_Rank'], df['Consistency_Rank'])\n",
    "\n",
    "        # 결과 출력\n",
    "        print(f\"Spearman correlation between Total Downloads and Growth Rate: {spearman_corr_total_growth}, P-value: {p_value_total_growth}\")\n",
    "        print(f\"Spearman correlation between Total Downloads and Consistency: {spearman_corr_total_consistency}, P-value: {p_value_total_consistency}\")\n",
    "        print(f\"Spearman correlation between Growth Rate and Consistency: {spearman_corr_growth_consistency}, P-value: {p_value_growth_consistency}\")\n",
    "\n",
    "        merged_df['row_mean'] = merged_df[['inc_sort_score', 'sum_score', 'consistency_score']].mean(axis=1)\n",
    "        mean_df = merged_df.sort_values(by='row_mean', ascending=False)\n",
    "        mean_df.to_csv('20240616_모델_순위.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor = DownloadDataProcessor('20240617_Daily_Download.csv')\n",
    "    processor.process_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
